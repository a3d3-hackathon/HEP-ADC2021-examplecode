{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a39aa96",
   "metadata": {},
   "source": [
    "# Detecting anomalies from HEP data with Generative Adversarial Networks\n",
    "\n",
    "(Someone smarter than me introduce the physics/objectives)\n",
    "\n",
    "We'll train a generative adversarial network (GAN) to build a generator network that can simulate samples from the training distribution, while simultaneously building a discriminator network that learns to distinguish real training samples from simulated ones. This requires the discriminator to build a robust representation of the training distribution (provided you've trained a sufficiently good generator). Then when we want to detect new anomalous events, we ditch the generator and just run new samples through the discriminator. Samples that are unlikely under the training distribution (and which are therefore likely to be anomalies) will then be ranked more highly by the discriminator, and we can use its output as a detection statistic.\n",
    "\n",
    "A good chunk of the GAN training code (and its sometimes obnoxious comments) comes from [this official Keras example](https://keras.io/guides/writing_a_training_loop_from_scratch/).\n",
    "\n",
    "Begin by doing our imports and defining some hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f79dab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 18:04:27.197515: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-13 18:04:28.526999: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"de585750-77a6-42f7-8555-5ab05201498b\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"de585750-77a6-42f7-8555-5ab05201498b\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.0.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"de585750-77a6-42f7-8555-5ab05201498b\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"de585750-77a6-42f7-8555-5ab05201498b\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.0.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"de585750-77a6-42f7-8555-5ab05201498b\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.palettes import Dark2_8 as palette\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "# Basic params\n",
    "BATCH_SIZE = 8192\n",
    "LATENT_DIM = 32  # dimension of the latent vector the generator samples\n",
    "VALID_FRAC = 0.25  # fraction of background/signal datasets to use for validation\n",
    "SEED = 101588  # random seed\n",
    "NUM_TRAIN_SAMPLES = 5000000  # you know what it is\n",
    "\n",
    "# Optimization params\n",
    "GEN_UPDATES = 8  # number of gradient updates to perform to the\n",
    "                 # generator in between updates to the discriminator\n",
    "D_LR = 0.0003  # learning rate for the discriminator\n",
    "G_LR = 0.0008  # learning rate for the generator\n",
    "FPR_THRESH = 1e-5  # false positive rate to use during validation\n",
    "\n",
    "# paths and what not\n",
    "BACKGROUND_FNAME = Path(\"background.h5\")\n",
    "SIGNAL_FNAMES = {\n",
    "    \"A-4_leptons\": \"https://zenodo.org/record/7152590/files/Ato4l_lepFilter_13TeV_filtered.h5?download=1\",\n",
    "    \"leptoquarks-b_tau\": \"https://zenodo.org/record/7152599/files/leptoquark_LOWMASS_lepFilter_13TeV_filtered.h5?download=1\",\n",
    "    \"h_0-tau_tau\": \"https://zenodo.org/record/7152614/files/hToTauTau_13TeV_PU20_filtered.h5?download=1\",\n",
    "    \"h_plus-tau_nu\": \"https://zenodo.org/record/7152617/files/hChToTauNu_13TeV_PU20_filtered.h5?download=1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a672d95f",
   "metadata": {},
   "source": [
    "Next we'll download the challenge datasets from Zenodo, caching them for later use. This will take 1-2GB worth of disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14753bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(fname, url):\n",
    "    subprocess.run(f\"wget -O {fname} {url}\", shell=True)\n",
    "    \n",
    "if not BACKGROUND_FNAME.exists():\n",
    "    download_dataset(\n",
    "        str(BACKGROUND_FNAME),\n",
    "        \"https://zenodo.org/record/5046428/files/background_for_training.h5?download=1\"\n",
    "    )\n",
    "\n",
    "for signal, url in SIGNAL_FNAMES.items():\n",
    "    fname = signal + \".h5\"\n",
    "    if not Path(fname).exists():\n",
    "        download_dataset(fname, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c39d7",
   "metadata": {},
   "source": [
    "Start by loading in the background data and seeing how many events we have and look at what our features represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58a3025a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: Pt, Eta, Phi, Class\n",
      "Event types: MET_class_1, Four_Ele_class_2, Four_Mu_class_3, Ten_Jet_class_4\n",
      "Total background events: 13451915\n",
      "Loading 5000000 events\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(dataset, N):\n",
    "    X = dataset[:N]\n",
    "\n",
    "    # each dataset has 4 columns along its last dimension,\n",
    "    # the last of which represents a mask indicating whether\n",
    "    # that particle recorded any values for this sample.\n",
    "    # Break out that colum separately to use as a separate\n",
    "    # feature vector to the network.\n",
    "    X, y = np.split(X, [3], axis=-1)\n",
    "    return X, y[:, :, 0]\n",
    "\n",
    "\n",
    "with h5py.File(BACKGROUND_FNAME, \"r\") as f:\n",
    "    print(\"Features:\", \", \".join([i.decode() for i in f[\"Particles_Names\"][:]]))\n",
    "    print(\"Event types:\", \", \".join([i.decode() for i in f[\"Particles_Classes\"][:]]))\n",
    "    print(\"Total background events:\", len(f[\"Particles\"]))\n",
    "    print(f\"Loading {NUM_TRAIN_SAMPLES} events\")\n",
    "    X, masks = load_dataset(f[\"Particles\"], NUM_TRAIN_SAMPLES)\n",
    "\n",
    "_, num_events, num_features = X.shape\n",
    "FEATURE_DIM = num_events * num_features\n",
    "X = X.reshape(-1, FEATURE_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f97b9fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train_bg_events,\n",
    "    valid_bg_events,\n",
    "    train_bg_masks,\n",
    "    valid_bg_masks\n",
    ") = train_test_split(X, masks, test_size=VALID_FRAC, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a6fa374",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_bg_events)\n",
    "\n",
    "def preprocess(X, mask):\n",
    "    X = scaler.transform(X)\n",
    "    X = X.reshape(-1, num_events, num_features)\n",
    "    X[mask == 0] *= 0\n",
    "    X = X.reshape(-1, FEATURE_DIM)\n",
    "    return X\n",
    "\n",
    "train_bg_events = preprocess(train_bg_events, train_bg_masks)\n",
    "valid_bg_events = preprocess(valid_bg_events, valid_bg_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e401d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 13992 events from signal A-4_leptons\n",
      "Loading 172820 events from signal h_0-tau_tau\n",
      "Loading 190068 events from signal h_plus-tau_nu\n",
      "Loading 85136 events from signal leptoquarks-b_tau\n"
     ]
    }
   ],
   "source": [
    "valid_events = [valid_bg_events]\n",
    "valid_masks = [valid_bg_masks]\n",
    "valid_y = [np.zeros((len(valid_bg_events), 1))]\n",
    "\n",
    "signals = sorted(SIGNAL_FNAMES)\n",
    "for i, signal in enumerate(signals):\n",
    "    with h5py.File(signal + \".h5\", \"r\") as f:\n",
    "        dataset = f[\"Particles\"]\n",
    "        n = int(0.25 * len(dataset))\n",
    "        print(f\"Loading {n} events from signal {signal}\")\n",
    "        events, masks = load_dataset(dataset, n)\n",
    "\n",
    "    events = events.reshape(-1, FEATURE_DIM)\n",
    "    events = preprocess(events, masks)\n",
    "    valid_events.append(events)\n",
    "    valid_masks.append(masks)\n",
    "\n",
    "    classes = np.ones((n, 1)) * (i + 1)\n",
    "    valid_y.append(classes)\n",
    "\n",
    "valid_y = np.concatenate(valid_y)\n",
    "valid_events = np.concatenate(valid_events)\n",
    "valid_masks = np.concatenate(valid_masks)\n",
    "\n",
    "idx = np.random.permutation(len(valid_y))\n",
    "valid_y = valid_y[idx]\n",
    "valid_events = valid_events[idx]\n",
    "valid_masks = valid_masks[idx]\n",
    "\n",
    "valid_X = (valid_events, valid_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae6da00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 18:05:13.804099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14605 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "generator_input = tf.keras.Input((LATENT_DIM,))\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(generator_input)\n",
    "x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "generator_output = tf.keras.layers.Dense(FEATURE_DIM, activation=\"linear\")(x)\n",
    "generator_mask = tf.keras.layers.Dense(num_events, activation=\"sigmoid\")(x)\n",
    "generator = tf.keras.Model(\n",
    "    inputs=generator_input,\n",
    "    outputs=[generator_output, generator_mask]\n",
    ")\n",
    "\n",
    "discriminator_input = tf.keras.Input((FEATURE_DIM,))\n",
    "disc_x = tf.keras.layers.Dense(256, activation=\"relu\")(discriminator_input)\n",
    "disc_x = tf.keras.layers.Dense(128, activation=\"relu\")(disc_x)\n",
    "disc_x = tf.keras.layers.Dense(64, activation=\"relu\")(disc_x)\n",
    "\n",
    "discriminator_mask = tf.keras.Input((num_events,))\n",
    "disc_mask = tf.keras.layers.Dense(256, activation=\"relu\")(discriminator_mask)\n",
    "disc_mask = tf.keras.layers.Dense(128, activation=\"relu\")(disc_mask)\n",
    "disc_mask = tf.keras.layers.Dense(64, activation=\"relu\")(disc_mask)\n",
    "\n",
    "disc_x = tf.keras.layers.Concatenate()([disc_x, disc_mask])\n",
    "disc_x = tf.keras.layers.Dense(256, activation=\"relu\")(disc_x)\n",
    "disc_x = tf.keras.layers.Dense(512, activation=\"relu\")(disc_x)\n",
    "disc_x = tf.keras.layers.Dense(1, activation=\"linear\")(disc_x)\n",
    "discriminator = tf.keras.Model(\n",
    "    inputs=[discriminator_input, discriminator_mask],\n",
    "    outputs=disc_x\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4caf63",
   "metadata": {},
   "source": [
    "Can't seem to get this custom metric to work, so using a custom training loop below. But someone smarter than I should figure this out so we can just use `Model.fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c4bdf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TPR(tf.keras.metrics.Metric):\n",
    "    def __init__(self, k, **kwargs):\n",
    "        self.k = k\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def reset_state(self):\n",
    "        # TODO: maybe these states need to be registered as variables?\n",
    "        # Also not sure what happens with `reset_state` if we don't pass\n",
    "        # the metric to `Model.compile`\n",
    "        self.background_preds = tf.convert_to_tensor(())\n",
    "        self.signal_preds = tf.convert_to_tensor(())\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        background = y_pred[y_true == 0]\n",
    "        self.background_preds = tf.concat([self.background_preds, background], axis=0)\n",
    "\n",
    "        signal = y_pred[y_true == 1]\n",
    "        self.signal_preds = tf.concat([self.signal_preds, signal], axis=0)\n",
    "\n",
    "    def result(self):\n",
    "        k = tf.shape(self.background_preds)[0] - self.k\n",
    "        threshold = tf.sort(self.background_preds)[k]\n",
    "        mask = self.signal_preds > threshold\n",
    "        mask = tf.cast(mask, tf.int64)\n",
    "        tpr = tf.math.reduce_mean(mask)\n",
    "        return tpr\n",
    "\n",
    "threshold_k = int(FPR_THRESH * len(valid_bg_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb36f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def fudge_mask(mask, noisy=True):\n",
    "    mask = tf.where(mask == 0, -10., 10.)\n",
    "    if noisy:\n",
    "        eps = tf.random.normal(shape=(BATCH_SIZE, num_events))\n",
    "        eps = eps[:tf.shape(mask)[0]]\n",
    "        mask = mask + eps\n",
    "    return tf.sigmoid(mask)\n",
    "\n",
    "\n",
    "class GAN(tf.keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim, gen_updates):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_updates = gen_updates\n",
    "\n",
    "        self.d_loss_tracker = tf.keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_tracker = tf.keras.metrics.Mean(name=\"g_loss\")\n",
    "        self.tpr = tf.keras.metrics.SensitivityAtSpecificity(1 - FPR_THRESH)\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def step_generator(self, batch_size):\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = discriminator(generator(random_latent_vectors))\n",
    "            g_loss = loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, generator.trainable_weights)\n",
    "        g_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n",
    "        return g_loss\n",
    "\n",
    "    def train_step(self, X):\n",
    "        real_events, real_mask = X\n",
    "        batch_size = tf.shape(real_events)[0]\n",
    "\n",
    "        # train the generator for multiple steps\n",
    "        # in between a single step of the discriminator\n",
    "        g_loss = 0\n",
    "        for i in range(self.gen_updates):\n",
    "            g_loss += self.step_generator(batch_size)\n",
    "        g_loss /= self.gen_updates\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Decode them to fake events\n",
    "        generated_events, generated_mask = generator(random_latent_vectors)\n",
    "\n",
    "        # Combine them with real events\n",
    "        combined_events = tf.concat([generated_events, real_events], axis=0)\n",
    "        combined_masks = tf.concat([generated_mask, real_mask], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake events\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform((2 * batch_size, 1))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = discriminator([combined_events, combined_masks])\n",
    "            d_loss = loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, discriminator.trainable_weights)\n",
    "        d_optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
    "\n",
    "        self.d_loss_tracker.update_state(d_loss)\n",
    "        self.g_loss_tracker.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_tracker.result(),\n",
    "            \"g_loss\": self.g_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "        events, masks = x\n",
    "        masks = fudge_mask(masks, noisy=False)\n",
    "\n",
    "        # Compute predictions\n",
    "        y_pred = self.discriminator((events, masks), training=False)\n",
    "\n",
    "        # Updates the metrics tracking the loss\n",
    "        self.tpr.update_state(y, y_pred)\n",
    "        return {\"tpr\": self.tpr.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1b030f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_optimizer = tf.keras.optimizers.Adam(learning_rate=D_LR)\n",
    "g_optimizer = tf.keras.optimizers.Adam(learning_rate=G_LR)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "gan = GAN(discriminator, generator, LATENT_DIM, GEN_UPDATES)\n",
    "gan.compile(d_optimizer, g_optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faaa13bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|                                                                                               | 0/458 [00:00<?, ?it/s]2023-07-13 18:05:29.612507: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f50b0d87640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-13 18:05:29.612543: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
      "2023-07-13 18:05:29.620432: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-13 18:05:32.998260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-07-13 18:05:33.122702: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "Epoch 1: 100%|██████████████████████████████████████| 458/458 [00:41<00:00, 11.09it/s, discriminator_loss=2.01, generator_loss=0.486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 2.008e+00, Generator Loss 4.859e-01\n",
      "Valid TPR: 1.214e-03\n",
      "A-4_leptons: 3.009%\th_0-tau_tau: 0.035%\th_plus-tau_nu: 0.026%\tleptoquarks-b_tau: 0.034%\n",
      "Achieved new best score! Saving weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████| 458/458 [00:21<00:00, 21.81it/s, discriminator_loss=0.703, generator_loss=0.784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 7.035e-01, Generator Loss 7.844e-01\n",
      "Valid TPR: 7.143e-04\n",
      "A-4_leptons: 1.780%\th_0-tau_tau: 0.019%\th_plus-tau_nu: 0.016%\tleptoquarks-b_tau: 0.021%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████| 458/458 [00:20<00:00, 22.53it/s, discriminator_loss=-.0778, generator_loss=14.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -7.779e-02, Generator Loss 1.423e+01\n",
      "Valid TPR: 4.697e-04\n",
      "A-4_leptons: 1.215%\th_0-tau_tau: 0.012%\th_plus-tau_nu: 0.008%\tleptoquarks-b_tau: 0.014%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████████████████████████████████| 458/458 [00:21<00:00, 21.29it/s, discriminator_loss=0.204, generator_loss=9.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 2.043e-01, Generator Loss 9.530e+00\n",
      "Valid TPR: 7.705e-04\n",
      "A-4_leptons: 1.973%\th_0-tau_tau: 0.018%\th_plus-tau_nu: 0.017%\tleptoquarks-b_tau: 0.019%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████████████| 458/458 [00:20<00:00, 22.03it/s, discriminator_loss=0.711, generator_loss=0.744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 7.109e-01, Generator Loss 7.436e-01\n",
      "Valid TPR: 9.350e-04\n",
      "A-4_leptons: 2.358%\th_0-tau_tau: 0.024%\th_plus-tau_nu: 0.020%\tleptoquarks-b_tau: 0.026%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████████████████| 458/458 [00:20<00:00, 22.13it/s, discriminator_loss=0.706, generator_loss=0.737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 7.057e-01, Generator Loss 7.372e-01\n",
      "Valid TPR: 8.961e-04\n",
      "A-4_leptons: 2.280%\th_0-tau_tau: 0.023%\th_plus-tau_nu: 0.017%\tleptoquarks-b_tau: 0.027%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████████████████████████████████| 458/458 [00:20<00:00, 22.15it/s, discriminator_loss=0.685, generator_loss=1.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 6.852e-01, Generator Loss 1.156e+00\n",
      "Valid TPR: 9.805e-04\n",
      "A-4_leptons: 2.473%\th_0-tau_tau: 0.025%\th_plus-tau_nu: 0.021%\tleptoquarks-b_tau: 0.028%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████████████████████████████████| 458/458 [00:22<00:00, 20.66it/s, discriminator_loss=0.71, generator_loss=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 7.099e-01, Generator Loss 7.682e-01\n",
      "Valid TPR: 1.151e-03\n",
      "A-4_leptons: 2.923%\th_0-tau_tau: 0.029%\th_plus-tau_nu: 0.024%\tleptoquarks-b_tau: 0.033%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█████████████████████████████████████| 458/458 [00:20<00:00, 22.10it/s, discriminator_loss=0.703, generator_loss=0.737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 7.029e-01, Generator Loss 7.371e-01\n",
      "Valid TPR: 1.208e-03\n",
      "A-4_leptons: 3.080%\th_0-tau_tau: 0.029%\th_plus-tau_nu: 0.025%\tleptoquarks-b_tau: 0.034%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|████████████████████████████████████| 458/458 [00:20<00:00, 22.58it/s, discriminator_loss=0.707, generator_loss=0.774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 7.067e-01, Generator Loss 7.744e-01\n",
      "Valid TPR: 1.056e-03\n",
      "A-4_leptons: 2.680%\th_0-tau_tau: 0.025%\th_plus-tau_nu: 0.023%\tleptoquarks-b_tau: 0.031%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|████████████████████████████████████| 458/458 [00:21<00:00, 21.75it/s, discriminator_loss=0.701, generator_loss=0.742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 7.012e-01, Generator Loss 7.416e-01\n",
      "Valid TPR: 1.128e-03\n",
      "A-4_leptons: 2.823%\th_0-tau_tau: 0.030%\th_plus-tau_nu: 0.025%\tleptoquarks-b_tau: 0.032%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|████████████████████████████████████| 458/458 [00:20<00:00, 22.66it/s, discriminator_loss=0.687, generator_loss=0.799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 6.871e-01, Generator Loss 7.985e-01\n",
      "Valid TPR: 1.193e-03\n",
      "A-4_leptons: 2.995%\th_0-tau_tau: 0.032%\th_plus-tau_nu: 0.026%\tleptoquarks-b_tau: 0.032%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|█████████████████████████████████████| 458/458 [00:21<00:00, 20.89it/s, discriminator_loss=0.577, generator_loss=1.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 5.771e-01, Generator Loss 1.346e+00\n",
      "Valid TPR: 7.467e-04\n",
      "A-4_leptons: 1.787%\th_0-tau_tau: 0.020%\th_plus-tau_nu: 0.021%\tleptoquarks-b_tau: 0.023%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████████████████████████████████| 458/458 [00:20<00:00, 22.48it/s, discriminator_loss=0.46, generator_loss=1.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 4.596e-01, Generator Loss 1.815e+00\n",
      "Valid TPR: 7.900e-04\n",
      "A-4_leptons: 1.937%\th_0-tau_tau: 0.020%\th_plus-tau_nu: 0.022%\tleptoquarks-b_tau: 0.022%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|█████████████████████████████████████| 458/458 [00:20<00:00, 22.84it/s, discriminator_loss=0.266, generator_loss=2.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 2.665e-01, Generator Loss 2.108e+00\n",
      "Valid TPR: 7.034e-04\n",
      "A-4_leptons: 1.708%\th_0-tau_tau: 0.019%\th_plus-tau_nu: 0.019%\tleptoquarks-b_tau: 0.019%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|█████████████████████████████████████| 458/458 [00:20<00:00, 22.77it/s, discriminator_loss=0.188, generator_loss=8.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 1.879e-01, Generator Loss 8.688e+00\n",
      "Valid TPR: 7.446e-04\n",
      "A-4_leptons: 1.830%\th_0-tau_tau: 0.017%\th_plus-tau_nu: 0.018%\tleptoquarks-b_tau: 0.028%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|█████████████████████████████████████| 458/458 [00:20<00:00, 22.52it/s, discriminator_loss=-.131, generator_loss=15.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: -1.308e-01, Generator Loss 1.525e+01\n",
      "Valid TPR: 6.472e-04\n",
      "A-4_leptons: 1.644%\th_0-tau_tau: 0.012%\th_plus-tau_nu: 0.014%\tleptoquarks-b_tau: 0.026%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████████████████████████████████| 458/458 [00:21<00:00, 20.92it/s, discriminator_loss=0.44, generator_loss=5.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 4.398e-01, Generator Loss 5.880e+00\n",
      "Valid TPR: 7.705e-04\n",
      "A-4_leptons: 1.865%\th_0-tau_tau: 0.021%\th_plus-tau_nu: 0.020%\tleptoquarks-b_tau: 0.025%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|████████████████████████████████████| 458/458 [00:22<00:00, 20.76it/s, discriminator_loss=0.688, generator_loss=0.948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 6.885e-01, Generator Loss 9.477e-01\n",
      "Valid TPR: 8.030e-04\n",
      "A-4_leptons: 1.930%\th_0-tau_tau: 0.021%\th_plus-tau_nu: 0.023%\tleptoquarks-b_tau: 0.025%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|█████████████████████████████████████| 458/458 [00:20<00:00, 22.29it/s, discriminator_loss=0.645, generator_loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss: 6.451e-01, Generator Loss 1.478e+00\n",
      "Valid TPR: 7.814e-04\n",
      "A-4_leptons: 1.872%\th_0-tau_tau: 0.023%\th_plus-tau_nu: 0.022%\tleptoquarks-b_tau: 0.021%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21:   5%|██                                     | 24/458 [00:02<00:43, 10.08it/s, discriminator_loss=0.65, generator_loss=1.29]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(dataset, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pbar):\n\u001b[0;32m---> 14\u001b[0m         losses \u001b[38;5;241m=\u001b[39m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m         epoch_losses \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;241m+\u001b[39m j \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(losses, epoch_losses)]\n\u001b[1;32m     16\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mset_postfix(\n\u001b[1;32m     17\u001b[0m             discriminator_loss\u001b[38;5;241m=\u001b[39mepoch_losses[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) ,\n\u001b[1;32m     18\u001b[0m             generator_loss\u001b[38;5;241m=\u001b[39mepoch_losses[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/hep-hackathon/lib/python3.10/site-packages/keras/src/engine/training.py:2684\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2680\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[1;32m   2681\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[1;32m   2682\u001b[0m     )\n\u001b[1;32m   2683\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[0;32m-> 2684\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2686\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/miniconda3/envs/hep-hackathon/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/hep-hackathon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/hep-hackathon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/hep-hackathon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hep-hackathon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/hep-hackathon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/envs/hep-hackathon/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/hep-hackathon/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "events = tf.data.Dataset.from_tensor_slices(train_bg_events.astype(\"float32\"))\n",
    "masks = tf.data.Dataset.from_tensor_slices(train_bg_masks.astype(\"float32\"))\n",
    "\n",
    "dataset = tf.data.Dataset.zip((events, masks))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "dataset = dataset.map(lambda e, m: (e, fudge_mask(m)))\n",
    "\n",
    "losses, tprs = [], []\n",
    "best_score = 0\n",
    "for epoch in range(100):\n",
    "    epoch_losses = [0, 0]\n",
    "    with tqdm(dataset, desc=f\"Epoch {epoch + 1}\") as pbar:\n",
    "        for step, x in enumerate(pbar):\n",
    "            losses = gan.train_on_batch(*x)\n",
    "            epoch_losses = [i + j for i, j in zip(losses, epoch_losses)]\n",
    "            pbar.set_postfix(\n",
    "                discriminator_loss=epoch_losses[0] / (step + 1) ,\n",
    "                generator_loss=epoch_losses[1] / (step + 1)\n",
    "            )\n",
    "        \n",
    "    epoch_losses = [i / len(dataset) for i in epoch_losses]\n",
    "    print(\n",
    "        \"Discriminator Loss: {:0.3e}, Generator Loss {:0.3e}\".format(\n",
    "            *epoch_losses\n",
    "        )\n",
    "    )\n",
    "    losses.append(epoch_losses)\n",
    "\n",
    "    masks = fudge_mask(valid_masks, noisy=False)\n",
    "    y_pred = discriminator((valid_events, masks), training=False).numpy()\n",
    "    thresh = np.sort(y_pred[valid_y == 0])[-threshold_k]\n",
    "    tpr = (y_pred[valid_y  > 0] >= thresh).mean()\n",
    "    print(f\"Valid TPR: {tpr:0.3e}\")\n",
    "    tprs.append(tpr)\n",
    "\n",
    "    per_signal = []\n",
    "    for i, signal in enumerate(signals):\n",
    "        signal_tpr = (y_pred[valid_y == (i + 1)] >= thresh).mean() * 100\n",
    "        per_signal.append(f\"{signal}: {signal_tpr:0.3f}%\")\n",
    "    print(\"\\t\".join(per_signal))\n",
    "        \n",
    "\n",
    "    if tpr > best_score:\n",
    "        best_score = tpr\n",
    "        print(\"Achieved new best score! Saving weights\")\n",
    "        discriminator.save_weights(\"checkpoints/discriminator\")\n",
    "        generator.save_weights(\"checkpoints/generator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012edab",
   "metadata": {},
   "source": [
    "Now load in the best version of our discriminator and visualize some of its predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a33fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.load_weights(\"checkpoints/discriminator\")\n",
    "\n",
    "masks = fudge_mask(valid_masks, noisy=False)\n",
    "y_pred = discriminator((valid_events, masks), training=False).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd25786e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"c8976c64-364a-423d-849c-9ebcd8b397bc\" data-root-id=\"p1001\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "  const docs_json = {\"e2856500-d80f-4998-a031-db5f8a8ddd80\":{\"version\":\"3.2.0\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1001\",\"attributes\":{\"width\":700,\"height\":300,\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1002\"},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1003\"},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1010\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LogScale\",\"id\":\"p1011\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1008\"},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1035\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1029\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1030\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1031\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"No/0OUlQJ0AyvBu6I/0pQC7pQjr+qSxAKBZquthWL0CSoUid2QExQBA4XN1GWDJAjc5vHbSuM0ALZYNdIQU1QIn7lp2OWzZAB5Kq3fuxN0CEKL4daQg5QAK/0V3WXjpAf1XlnUO1O0D96/jdsAs9QHuCDB4eYj5A+RggXou4P0C81xlPfIdAQPqiI++yMkFAOG4tj+ndQUB4OTcvIIlCQLYEQc9WNENA9s9Kb43fQ0A0m1QPxIpEQHNmXq/6NUVAsjFoTzHhRUDw/HHvZ4xGQDDIe4+eN0dAbpOFL9XiR0CtXo/PC45IQOwpmW9COUlAKvWiD3nkSUBqwKyvr49KQKiLtk/mOktA6FbA7xzmS0AmIsqPU5FMQGXt0y+KPE1ApLjdz8DnTUDig+dv95JOQCJP8Q8uPk9AYBr7r2TpT0A=\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}],[\"top\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"doMN9PUhxD5Ir7ya8te6PkivvJry16o+SK+8mvLXuj5Ir7ya8te6PkivvJry13o+SK+8mvLXqj5Ir7ya8td6PkivvJry16o+SK+8mvLXej5Ir7ya8td6PkivvJry16o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej4=\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1036\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1037\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1032\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":1.3376045272657304},\"bottom\":{\"type\":\"value\",\"value\":1e-07},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"#111111\"},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"value\",\"value\":\"#1b9e77\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.3}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1033\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":1.3376045272657304},\"bottom\":{\"type\":\"value\",\"value\":1e-07},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"#111111\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"value\",\"value\":\"#1b9e77\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1034\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":1.3376045272657304},\"bottom\":{\"type\":\"value\",\"value\":1e-07},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"#111111\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"value\",\"value\":\"#1b9e77\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1046\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1040\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1041\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1042\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"No/0OUlQJ0AyvBu6I/0pQC7pQjr+qSxAKBZquthWL0CSoUid2QExQBA4XN1GWDJAjc5vHbSuM0ALZYNdIQU1QIn7lp2OWzZAB5Kq3fuxN0CEKL4daQg5QAK/0V3WXjpAf1XlnUO1O0D96/jdsAs9QHuCDB4eYj5A+RggXou4P0C81xlPfIdAQPqiI++yMkFAOG4tj+ndQUB4OTcvIIlCQLYEQc9WNENA9s9Kb43fQ0A0m1QPxIpEQHNmXq/6NUVAsjFoTzHhRUDw/HHvZ4xGQDDIe4+eN0dAbpOFL9XiR0CtXo/PC45IQOwpmW9COUlAKvWiD3nkSUBqwKyvr49KQKiLtk/mOktA6FbA7xzmS0AmIsqPU5FMQGXt0y+KPE1ApLjdz8DnTUDig+dv95JOQCJP8Q8uPk9AYBr7r2TpT0A=\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}],[\"top\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"qiGywysBeD9tuMTA7zJ0P95NPNT+53M/jUyh6klrZz8wT9e9s2RwPzxLBgGV7lo/wXgr+xxSYz+NTKHqSWtXP+tJaxfgcU4/jUyh6klrRz+NTKHqSWtHP3b1J7NYGjw/jUyh6klrNz+koxoiO7wSP6SjGiI7vDI/SK+8mvLXej6koxoiO7wSP6SjGiI7vBI/dvUns1gaLD9Ir7ya8td6PqSjGiI7vBI/SK+8mvLXej6koxoiO7wSP0ivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+pKMaIju8Ej8=\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1047\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1048\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1043\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":1.3376045272657304},\"bottom\":{\"type\":\"value\",\"value\":1e-07},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"#111111\"},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"value\",\"value\":\"#d95f02\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.3}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1044\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":1.3376045272657304},\"bottom\":{\"type\":\"value\",\"value\":1e-07},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"#111111\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"value\",\"value\":\"#d95f02\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1045\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":1.3376045272657304},\"bottom\":{\"type\":\"value\",\"value\":1e-07},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"#111111\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"value\",\"value\":\"#d95f02\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1056\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1050\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1051\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1052\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"No/0OUlQJ0AyvBu6I/0pQC7pQjr+qSxAKBZquthWL0CSoUid2QExQBA4XN1GWDJAjc5vHbSuM0ALZYNdIQU1QIn7lp2OWzZAB5Kq3fuxN0CEKL4daQg5QAK/0V3WXjpAf1XlnUO1O0D96/jdsAs9QHuCDB4eYj5A+RggXou4P0C81xlPfIdAQPqiI++yMkFAOG4tj+ndQUB4OTcvIIlCQLYEQc9WNENA9s9Kb43fQ0A0m1QPxIpEQHNmXq/6NUVAsjFoTzHhRUDw/HHvZ4xGQDDIe4+eN0dAbpOFL9XiR0CtXo/PC45IQOwpmW9COUlAKvWiD3nkSUBqwKyvr49KQKiLtk/mOktA6FbA7xzmS0AmIsqPU5FMQGXt0y+KPE1ApLjdz8DnTUDig+dv95JOQCJP8Q8uPk9AYBr7r2TpT0A=\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}],[\"top\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"JIZdeG48FT9wffaAv8AWP1NjwZqyTQs/JIZdeG48BT+NlytnzDPyPrx0j4kQRfg+vHSPiRBF+D68dI+JEEXYPrx0j4kQRfg+jZcrZ8wz8j68dI+JEEXYPrx0j4kQReg+vHSPiRBF2D5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej4=\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1057\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1058\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1053\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":1.3376045272657304},\"bottom\":{\"type\":\"value\",\"value\":1e-07},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"#111111\"},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"value\",\"value\":\"#7570b3\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.3}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1054\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":1.3376045272657304},\"bottom\":{\"type\":\"value\",\"value\":1e-07},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"#111111\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"value\",\"value\":\"#7570b3\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1055\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":1.3376045272657304},\"bottom\":{\"type\":\"value\",\"value\":1e-07},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"#111111\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"value\",\"value\":\"#7570b3\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1066\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1060\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1061\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1062\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"No/0OUlQJ0AyvBu6I/0pQC7pQjr+qSxAKBZquthWL0CSoUid2QExQBA4XN1GWDJAjc5vHbSuM0ALZYNdIQU1QIn7lp2OWzZAB5Kq3fuxN0CEKL4daQg5QAK/0V3WXjpAf1XlnUO1O0D96/jdsAs9QHuCDB4eYj5A+RggXou4P0C81xlPfIdAQPqiI++yMkFAOG4tj+ndQUB4OTcvIIlCQLYEQc9WNENA9s9Kb43fQ0A0m1QPxIpEQHNmXq/6NUVAsjFoTzHhRUDw/HHvZ4xGQDDIe4+eN0dAbpOFL9XiR0CtXo/PC45IQOwpmW9COUlAKvWiD3nkSUBqwKyvr49KQKiLtk/mOktA6FbA7xzmS0AmIsqPU5FMQGXt0y+KPE1ApLjdz8DnTUDig+dv95JOQCJP8Q8uPk9AYBr7r2TpT0A=\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}],[\"top\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"jvZsS5CVCz8D3PdSuFcOPxoR4kNo0wg/pStXPEAR1j6lK1c8QBH2PqUrVzxAEeY+pStXPEAR9j68YEEt8IwAP6UrVzxAEfY+pStXPEAR1j6lK1c8QBHWPkivvJry13o+pStXPEAR1j5Ir7ya8td6PkivvJry13o+SK+8mvLXej6lK1c8QBHWPkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej4=\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1067\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1068\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1063\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":1.3376045272657304},\"bottom\":{\"type\":\"value\",\"value\":1e-07},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"#111111\"},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"value\",\"value\":\"#e7298a\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.3}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1064\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":1.3376045272657304},\"bottom\":{\"type\":\"value\",\"value\":1e-07},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"#111111\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"value\",\"value\":\"#e7298a\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1065\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":1.3376045272657304},\"bottom\":{\"type\":\"value\",\"value\":1e-07},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"#111111\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"value\",\"value\":\"#e7298a\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1076\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1070\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1071\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1072\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"No/0OUlQJ0AyvBu6I/0pQC7pQjr+qSxAKBZquthWL0CSoUid2QExQBA4XN1GWDJAjc5vHbSuM0ALZYNdIQU1QIn7lp2OWzZAB5Kq3fuxN0CEKL4daQg5QAK/0V3WXjpAf1XlnUO1O0D96/jdsAs9QHuCDB4eYj5A+RggXou4P0C81xlPfIdAQPqiI++yMkFAOG4tj+ndQUB4OTcvIIlCQLYEQc9WNENA9s9Kb43fQ0A0m1QPxIpEQHNmXq/6NUVAsjFoTzHhRUDw/HHvZ4xGQDDIe4+eN0dAbpOFL9XiR0CtXo/PC45IQOwpmW9COUlAKvWiD3nkSUBqwKyvr49KQKiLtk/mOktA6FbA7xzmS0AmIsqPU5FMQGXt0y+KPE1ApLjdz8DnTUDig+dv95JOQCJP8Q8uPk9AYBr7r2TpT0A=\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}],[\"top\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"0/wx6Qmi+D7T/DHpCaIYPzm9C6zIjRU/nn3lbod5Aj/T/DHpCaIIP9P8MekJoug+0/wx6Qmi6D5Ir7ya8td6PtP8MekJoug+SK+8mvLXej7T/DHpCaLoPtP8MekJoug+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej5Ir7ya8td6PkivvJry13o+SK+8mvLXej4=\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1077\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1078\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1073\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":1.3376045272657304},\"bottom\":{\"type\":\"value\",\"value\":1e-07},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"#111111\"},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"value\",\"value\":\"#66a61e\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.3}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1074\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":1.3376045272657304},\"bottom\":{\"type\":\"value\",\"value\":1e-07},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"#111111\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"value\",\"value\":\"#66a61e\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1075\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":1.3376045272657304},\"bottom\":{\"type\":\"value\",\"value\":1e-07},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"#111111\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":1.5},\"fill_color\":{\"type\":\"value\",\"value\":\"#66a61e\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1009\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1022\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1023\"},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1024\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1025\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"bottom_units\":\"canvas\",\"top_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1026\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1027\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1028\"}]}},\"toolbar_location\":null,\"left\":[{\"type\":\"object\",\"name\":\"LogAxis\",\"id\":\"p1017\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"LogTicker\",\"id\":\"p1018\",\"attributes\":{\"num_minor_ticks\":10,\"mantissas\":[1,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"LogTickFormatter\",\"id\":\"p1019\"},\"axis_label\":\"Fraction in bin\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1020\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1012\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1013\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1014\"},\"axis_label\":\"Discriminator Score\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1015\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1016\",\"attributes\":{\"axis\":{\"id\":\"p1012\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1021\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1017\"}}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1038\",\"attributes\":{\"click_policy\":\"hide\",\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1039\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Background\"},\"renderers\":[{\"id\":\"p1035\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1049\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"A-4_leptons\"},\"renderers\":[{\"id\":\"p1046\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1059\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"h_0-tau_tau\"},\"renderers\":[{\"id\":\"p1056\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1069\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"h_plus-tau_nu\"},\"renderers\":[{\"id\":\"p1066\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1079\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"leptoquarks-b_tau\"},\"renderers\":[{\"id\":\"p1076\"}]}}]}}]}}]}};\n",
       "  const render_items = [{\"docid\":\"e2856500-d80f-4998-a031-db5f8a8ddd80\",\"roots\":{\"p1001\":\"c8976c64-364a-423d-849c-9ebcd8b397bc\"},\"root_ids\":[\"p1001\"]}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p1001"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = figure(\n",
    "    height=300,\n",
    "    width=700,\n",
    "    y_axis_type=\"log\",\n",
    "    x_axis_label=\"Discriminator Score\",\n",
    "    y_axis_label=\"Fraction in bin\"\n",
    ")\n",
    "p.toolbar_location = None\n",
    "\n",
    "# only look at predictions above the FPR threshold\n",
    "bg_preds = y_pred[valid_y == 0]\n",
    "thresh = np.percentile(bg_preds, 100 * (1 - FPR_THRESH))\n",
    "bg_preds = bg_preds[bg_preds > thresh]\n",
    "bins = np.linspace(thresh, y_pred.max(), 41)\n",
    "\n",
    "bg, _ = np.histogram(bg_preds, bins=bins)\n",
    "bg = bg / (valid_y == 0).sum()\n",
    "\n",
    "def plot_hist(values, label, color):\n",
    "    p.vbar(\n",
    "        x=centers,\n",
    "        top=np.clip(values, 1e-7, 1),\n",
    "        bottom=1e-7,\n",
    "        width=width,\n",
    "        fill_color=color,\n",
    "        fill_alpha=0.3,\n",
    "        line_color=\"#111111\",\n",
    "        line_width=1.5,\n",
    "        legend_label=label\n",
    "    )\n",
    "    \n",
    "\n",
    "centers = (bins[:-1] + bins[1:]) / 2\n",
    "width = bins[1] - bins[0]\n",
    "plot_hist(bg, \"Background\", palette[0])\n",
    "\n",
    "for i, signal in enumerate(signals):\n",
    "    mask = valid_y == (i + 1)\n",
    "    fg_preds = y_pred[mask]\n",
    "    fg_preds = fg_preds[fg_preds > thresh]\n",
    "    hist, _ = np.histogram(fg_preds, bins)\n",
    "    hist = hist / mask.sum()\n",
    "    plot_hist(hist, signal, palette[i + 1])\n",
    "\n",
    "p.legend.click_policy = \"hide\"\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784474d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
